# Weather Analysis with Spark

Ce r√©pertoire contient un projet d'analyse de donn√©es m√©t√©orologiques non structur√©es en utilisant **Apache Spark**. L'objectif principal est d'√©valuer l'impact des conditions m√©t√©orologiques sur l'√©conomie des pays en analysant trois secteurs cl√©s :

- **Secteur de l'√©nergie** : √âtude de l'impact du froid sur la consommation d'√©lectricit√©.
- **Secteur des transports** : Analyse de l'impact des temp√™tes sur le trafic maritime.
- **Secteur de l'agriculture** : √âvaluation de l'impact des inondations sur le prix des denr√©es alimentaires.

## üìÇ Structure du projet

```
weather-analysis-with-spark/
‚îÇ‚Äî data/                     # Contient les donn√©es brutes et nettoy√©es
‚îÇ‚Äî notebooks/                # Jupyter notebooks pour l'exploration des donn√©es
‚îÇ‚Äî scripts/                  # Scripts Python pour le traitement et l'analyse des donn√©es
‚îÇ   ‚îÇ‚Äî analysis.py           # Script principal d'analyse
‚îÇ‚Äî results/                  # R√©sultats des analyses et visualisations
‚îÇ‚Äî presentation.ppt          # Pr√©sentation des r√©sultats
‚îÇ‚Äî requirements.txt          # Liste des d√©pendances du projet
‚îÇ‚Äî README.md                 # Documentation du projet
‚îÇ‚Äî link.txt                  # Contient les liens vers le dashboard des r√©sultats et les sources de donn√©es
```

##  Installation et Configuration

### Pr√©requis
Avant de commencer, assure-toi d'avoir install√© :
- **Python (‚â• 3.11)**
- **Apache Spark**
- **Jupyter Notebook**

### √âtapes d'installation
1. **Cloner le d√©p√¥t**
   ```bash
   git clone https://github.com/Hmd-02/weather-analysis-with-spark.git
   cd weather-analysis-with-spark
   ```
2. **Cr√©er un environnement virtuel (optionnel)**
   ```bash
   python -m venv venv
   source venv/bin/activate   # Sur macOS/Linux
   venv\Scripts\activate      # Sur Windows
   ```
3. **Installer les d√©pendances**
   ```bash
   pip install -r requirements.txt
   ```

##  Utilisation

1. **Ex√©cution de l'analyse**
   ```bash
   python scripts/analysis.py
   ```
2. **Exploration avec Jupyter Notebook**
   ```bash
   jupyter notebook notebooks/exploration.ipynb
   ```
3. **Acc√®s aux r√©sultats**
   - Les r√©sultats et visualisations seront disponibles dans le dossier **results/**.
   - Un dashboard interactif est accessible via le lien fourni dans `link.txt`.

##  Technologies utilis√©es

- **Apache Spark** : Traitement et analyse de donn√©es massives.
- **Pandas / NumPy** : Manipulation des donn√©es.
- **Matplotlib / Seaborn** : Visualisation des r√©sultats.
- **Streamlit** : Cr√©ation du dashboard interactif (optionnel).

##  M√©thodologie

1. **Collecte des donn√©es** : Extraction et transformation des donn√©es m√©t√©orologiques.
2. **Pr√©traitement** : Nettoyage, traitement des valeurs manquantes et structuration des donn√©es.
3. **Analyse exploratoire** : √âtude des tendances et corr√©lations.
4. **Mod√©lisation et visualisation** : G√©n√©ration de rapports et dashboards interactifs.

##  D√©ploiement

### Sur un serveur local
Si tu souhaites ex√©cuter le projet en local, utilise Streamlit pour afficher les r√©sultats :
```bash
streamlit run dashboard.py
```

---


